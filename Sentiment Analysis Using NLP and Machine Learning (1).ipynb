{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c584f126",
   "metadata": {},
   "source": [
    "# Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c570e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e532ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TSV file\n",
    "file_path = 'C:/Users/ANKITA/Downloads/amazon_alexa.tsv'\n",
    "reviews_df = pd.read_csv(file_path, sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1db56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['verified_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f456b9",
   "metadata": {},
   "source": [
    "# Exploring Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c561ade",
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.heatmap(reviews_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6235af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.hist(bins = 30, figsize = (13,5), color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ebd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['verified_reviews'] = reviews_df['verified_reviews'].fillna('').astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c998c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['length'] = reviews_df['verified_reviews'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cce4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['length'].plot(bins=100, kind='hist') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848066b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70815a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the longest message 43952\n",
    "reviews_df[reviews_df['length'] == 2851]['verified_reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d84b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the shortest message \n",
    "reviews_df[reviews_df['length'] == 1]['verified_reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a5648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the message with mean length \n",
    "reviews_df[reviews_df['length'] == 133]['verified_reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633af377",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = reviews_df[reviews_df['feedback']==1]\n",
    "negative = reviews_df[reviews_df['feedback']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e628d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f897a04",
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.countplot(x='feedback', data=reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb33933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'rating', data = reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea10d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['rating'].hist(bins = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd2928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (40,15))\n",
    "sns.barplot(x = 'variation', y='rating', data = reviews_df, palette = 'deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c731aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = reviews_df['verified_reviews'].tolist()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_as_one_string =\" \".join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15902c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_as_one_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cbcad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(WordCloud().generate(sentences_as_one_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ce35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_list = negative['verified_reviews'].tolist()\n",
    "\n",
    "negative_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28978f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sentences_as_one_string = \" \".join(negative_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4979cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(WordCloud().generate(negative_sentences_as_one_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8048a",
   "metadata": {},
   "source": [
    "# PERFORM DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the date, rating, length\n",
    "reviews_df = reviews_df.drop(['date', 'rating', 'length'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_dummies = pd.get_dummies(reviews_df['variation'], drop_first = True)\n",
    "# Avoid Dummy Variable trap which occurs when one variable can be predicted from the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6408db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's drop the column\n",
    "reviews_df.drop(['variation'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add the encoded column again\n",
    "reviews_df = pd.concat([reviews_df, variation_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d00286",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00642aa4",
   "metadata": {},
   "source": [
    "# REMOVING PUNCTUATION FROM TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4dcd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a pipeline to clean up all the messages \n",
    "# The pipeline performs the following: (1) remove punctuation, (2) remove stopwords\n",
    "\n",
    "def message_cleaning(message):\n",
    "    Test_punc_removed = [char for char in message if char not in string.punctuation]\n",
    "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
    "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n",
    "    return Test_punc_removed_join_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c62db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the newly added function\n",
    "reviews_df_clean = reviews_df['verified_reviews'].apply(message_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ac007",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_df_clean[3]) # show the cleaned up version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec15e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_df['verified_reviews'][3]) # show the original version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc5f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Define the cleaning pipeline we defined earlier\n",
    "vectorizer = CountVectorizer(analyzer = message_cleaning)\n",
    "reviews_countvectorizer = vectorizer.fit_transform(reviews_df['verified_reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b2013",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_countvectorizer.toarray())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7539af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_countvectorizer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcaf98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's drop the column\n",
    "reviews_df.drop(['verified_reviews'], axis=1, inplace=True)\n",
    "reviews = pd.DataFrame(reviews_countvectorizer.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b64a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's concatenate them together\n",
    "reviews_df = pd.concat([reviews_df, reviews], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661af563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the target label coloumns\n",
    "X = reviews_df.drop(['feedback'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reviews_df['feedback']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f287e0",
   "metadata": {},
   "source": [
    "#  Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1f461",
   "metadata": {},
   "source": [
    "# Naive Bayes Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed6af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains a Naive Bayes model.\n",
    "\n",
    "NB_classifier = MultinomialNB()\n",
    "NB_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_predict_train = NB_classifier.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e140ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, y_predict_train)\n",
    "sns.heatmap(cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf55e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays a confusion matrix for training predictions.\n",
    "\n",
    "y_predict_test = NB_classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "sns.heatmap(cm, annot=True)\n",
    "print(classification_report(y_test, y_predict_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173b995",
   "metadata": {},
   "source": [
    "# Logistic Regression Training and Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6406f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Set Performance\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aae80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print('Accuracy {} %'.format( 100 * accuracy_score(y_pred, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d13b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred, y_test)\n",
    "sns.heatmap(cm, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b87dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e460c",
   "metadata": {},
   "source": [
    "## Final Conclusion\n",
    "\n",
    "This project focused on analyzing Amazon Alexa customer reviews to predict whether customers are satisfied based on their written feedback.\n",
    "\n",
    "### Key Objectives:\n",
    "- Determine if a customer is **satisfied (1)** or **not satisfied (0)** using the review text.\n",
    "- Apply Natural Language Processing (NLP) techniques and machine learning models to build a reliable sentiment classifier.\n",
    "\n",
    "### What We Did:\n",
    "- Cleaned and preprocessed the review data by removing punctuation and stopwords\n",
    "- Explored the dataset through visualizations (word clouds, rating distribution, feedback count)\n",
    "- Converted text data into numeric features using `CountVectorizer`\n",
    "- Used one-hot encoding for product variation\n",
    "- Built and evaluated two models:\n",
    "  - **Naive Bayes**\n",
    "  - **Logistic Regression**\n",
    "\n",
    "### Results:\n",
    "- **Logistic Regression** performed best with an accuracy of **~95%**\n",
    "- Most customers in the dataset were **satisfied**, resulting in some class imbalance\n",
    "- Models struggled slightly with predicting the minority class (unsatisfied reviews)\n",
    "\n",
    "### Final Insight:\n",
    "**Yes, the majority of customers were satisfied with Amazon Alexa**, as shown by both the data distribution and model predictions.\n",
    "\n",
    "This project demonstrates how textual reviews can be effectively used to gain insights into customer sentiment using NLP and machine learning. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee120251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
